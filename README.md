# Sign_Langugage_Detection_ML_project2
Undergraduate Thesis Project 

Those who are deaf or hard of hearing primarily use sign language as a means of communication. People may readily express ideas and thoughts using this sort of gesture-based language, which removes obstacles brought on by challenges with hearing.

The fact that the vast majority of people on earth do not speak the language is a huge problem with this simple means of communication. Learning Sign Language requires a lot of time and work, just like learning any other language, which deters the general public from doing so.


Yet, the fields of machine learning and image detection have a clear solution to this problem. A type of real-time captioning for virtual reality can be made by utilizing predictive model technology to automatically classify Sign Language signals.

This project is a solution for this problem. I have used custom dataset for training this model.




