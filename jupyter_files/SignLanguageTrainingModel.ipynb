{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23YphP5l1h5Z"
      },
      "source": [
        "### Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "04Siixg01h5b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9oo6plRz1h5c",
        "outputId": "64cb3cb2-3f55-40b0-9054-0b181660aa84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.11.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "tf.__version__ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an7Dk1kR1h5d"
      },
      "source": [
        "### Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS53W8KA1h5d"
      },
      "source": [
        "#### Generating images for the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdTKBkRC1h5e"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu66NZJV1h5e"
      },
      "source": [
        "#### Generating images for the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwmX5k5Y1h5e"
      },
      "outputs": [],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/AvijitChowdhury/Sign-Language-To-Text-Conversion1/archive/refs/heads/main.zip\n",
        "\n"
      ],
      "metadata": {
        "id": "LVdw83N6ABOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y!unzip main.zip"
      ],
      "metadata": {
        "id": "5f9uFuWMAZeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tzI0ivH1h5e"
      },
      "source": [
        "### Creating the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1Qo_mdo1h5e",
        "outputId": "da6b7515-5b0f-48f9-e9a2-452bfa8cf62f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12845 images belonging to 27 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/Sign-Language-To-Text-Conversion1-main/dataSet/trainingData',                                \n",
        "                                                 target_size = (128, 128),\n",
        "                                                 batch_size = 10,\n",
        "                                                 color_mode = 'grayscale',                                \n",
        "                                                 class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmYk_kj-1h5e",
        "outputId": "4249185b-db0a-4a31-873d-f2f4cfb4ddf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4268 images belonging to 27 classes.\n"
          ]
        }
      ],
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/Sign-Language-To-Text-Conversion1-main/dataSet/testingData',\n",
        "                                            target_size = (128, 128),                                  \n",
        "                                            batch_size = 10,        \n",
        "                                            color_mode = 'grayscale',\n",
        "                                            class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Building CNN\n"
      ],
      "metadata": {
        "id": "M8xQkJVr6XkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing CNN"
      ],
      "metadata": {
        "id": "Yo2zQqEo6geq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "_mnL50fq6RJi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Convolution"
      ],
      "metadata": {
        "id": "L-GdKGtv60Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(tf.keras.layers.Conv2D(filters=32,\n",
        "                                     kernel_size=3, \n",
        "                                     padding=\"same\", \n",
        "                                     activation=\"relu\", \n",
        "                                     input_shape=[128, 128, 1]))"
      ],
      "metadata": {
        "id": "607kx-Kk62OT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2:  Pooling"
      ],
      "metadata": {
        "id": "0LyJeca969Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(tf.keras.layers.MaxPool2D(pool_size=2, \n",
        "                                         strides=2, \n",
        "                                         padding='valid'))"
      ],
      "metadata": {
        "id": "uUi1NDAZ68jS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding a second convolution layer"
      ],
      "metadata": {
        "id": "JH4SQSa_7HGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4ocZDlc57LhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(tf.keras.layers.Conv2D(filters=32, \n",
        "                                      kernel_size=3, \n",
        "                                      padding=\"same\", \n",
        "                                      activation=\"relu\"))\n",
        "\n",
        "classifier.add(tf.keras.layers.MaxPool2D(pool_size=2, \n",
        "                                         strides=2, \n",
        "                                         padding='valid'))"
      ],
      "metadata": {
        "id": "gE6Y-rGI7MEC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Flattering"
      ],
      "metadata": {
        "id": "p71AruP-7TAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "yFZZMQq27XhD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Full Connection"
      ],
      "metadata": {
        "id": "qImWKIur7aj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(tf.keras.layers.Dense(units=128, \n",
        "                                     activation='relu'))\n",
        "classifier.add(tf.keras.layers.Dropout(0.40))\n",
        "classifier.add(tf.keras.layers.Dense(units=96, activation='relu'))\n",
        "classifier.add(tf.keras.layers.Dropout(0.40))\n",
        "classifier.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "classifier.add(tf.keras.layers.Dense(units=27, activation='softmax')) # softmax for more than 2"
      ],
      "metadata": {
        "id": "WEQAyi6R7e5r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "blTX-KhS6zLx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpMe6KI41h5h"
      },
      "source": [
        "### Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vVwX9Uc1h5h"
      },
      "source": [
        "#### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Rjv_4Ki41h5h"
      },
      "outputs": [],
      "source": [
        "classifier.compile(optimizer = 'adam', \n",
        "                   loss = 'categorical_crossentropy', \n",
        "                   metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQr00ZUv1h5h"
      },
      "source": [
        "#### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2zK95Is1h5h",
        "outputId": "3130af52-fa1c-4095-eb6d-af08eee13ebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 128, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32768)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               4194432   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 96)                12384     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 96)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                6208      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 27)                1755      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,224,347\n",
            "Trainable params: 4,224,347\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "classifier.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcC8o0p71h5h",
        "outputId": "c3e25c5d-772b-4a77-a537-8b6e661237c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 369s 286ms/step - loss: 2.2999 - accuracy: 0.2848 - val_loss: 0.6703 - val_accuracy: 0.7706\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 345s 269ms/step - loss: 1.2500 - accuracy: 0.5682 - val_loss: 0.3310 - val_accuracy: 0.8868\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 371s 289ms/step - loss: 0.9769 - accuracy: 0.6634 - val_loss: 0.2009 - val_accuracy: 0.9517\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 341s 265ms/step - loss: 0.7751 - accuracy: 0.7370 - val_loss: 0.1501 - val_accuracy: 0.9330\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 358s 278ms/step - loss: 0.6786 - accuracy: 0.7752 - val_loss: 0.1553 - val_accuracy: 0.9492\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f17d8bbdd30>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "classifier.fit(training_set,\n",
        "                  epochs = 5,\n",
        "                  validation_data = test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TM4ZYOU1h5i"
      },
      "source": [
        "#### Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkVz44Uc1h5i",
        "outputId": "22e8b8d1-ece3-4cd2-c4dc-86d7b82f3de1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved\n",
            "Weights saved\n"
          ]
        }
      ],
      "source": [
        "model_json = classifier.to_json()\n",
        "with open(\"model_new.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "print('Model Saved')\n",
        "classifier.save_weights('model_new.h5')\n",
        "print('Weights saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7c-lEdS1h5i",
        "outputId": "d20a0b78-5393-4c28-fac1-6312c3afc789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1285/1285 [==============================] - 360s 281ms/step - loss: 0.6161 - accuracy: 0.8027 - val_loss: 0.0803 - val_accuracy: 0.9787\n",
            "Epoch 2/20\n",
            "1285/1285 [==============================] - 343s 267ms/step - loss: 0.5278 - accuracy: 0.8274 - val_loss: 0.0637 - val_accuracy: 0.9864\n",
            "Epoch 3/20\n",
            "1285/1285 [==============================] - 357s 278ms/step - loss: 0.4837 - accuracy: 0.8445 - val_loss: 0.0498 - val_accuracy: 0.9869\n",
            "Epoch 4/20\n",
            "1285/1285 [==============================] - 356s 277ms/step - loss: 0.4631 - accuracy: 0.8501 - val_loss: 0.0476 - val_accuracy: 0.9899\n",
            "Epoch 5/20\n",
            "1285/1285 [==============================] - 355s 276ms/step - loss: 0.4192 - accuracy: 0.8649 - val_loss: 0.0355 - val_accuracy: 0.9913\n",
            "Epoch 6/20\n",
            "1285/1285 [==============================] - 353s 274ms/step - loss: 0.4112 - accuracy: 0.8659 - val_loss: 0.0501 - val_accuracy: 0.9810\n",
            "Epoch 7/20\n",
            "1285/1285 [==============================] - 352s 274ms/step - loss: 0.3660 - accuracy: 0.8819 - val_loss: 0.0351 - val_accuracy: 0.9897\n",
            "Epoch 8/20\n",
            "1285/1285 [==============================] - 355s 276ms/step - loss: 0.3636 - accuracy: 0.8805 - val_loss: 0.0320 - val_accuracy: 0.9916\n",
            "Epoch 9/20\n",
            "1285/1285 [==============================] - 358s 279ms/step - loss: 0.3468 - accuracy: 0.8877 - val_loss: 0.0275 - val_accuracy: 0.9932\n",
            "Epoch 10/20\n",
            "1285/1285 [==============================] - 343s 267ms/step - loss: 0.3425 - accuracy: 0.8925 - val_loss: 0.0435 - val_accuracy: 0.9850\n",
            "Epoch 11/20\n",
            "1285/1285 [==============================] - 343s 267ms/step - loss: 0.3226 - accuracy: 0.8954 - val_loss: 0.0295 - val_accuracy: 0.9937\n",
            "Epoch 12/20\n",
            "1285/1285 [==============================] - 339s 264ms/step - loss: 0.3178 - accuracy: 0.8964 - val_loss: 0.0184 - val_accuracy: 0.9972\n",
            "Epoch 13/20\n",
            "1285/1285 [==============================] - 345s 269ms/step - loss: 0.2944 - accuracy: 0.9063 - val_loss: 0.0391 - val_accuracy: 0.9904\n",
            "Epoch 14/20\n",
            "1285/1285 [==============================] - 355s 276ms/step - loss: 0.3012 - accuracy: 0.9025 - val_loss: 0.0176 - val_accuracy: 0.9953\n",
            "Epoch 15/20\n",
            "1285/1285 [==============================] - 356s 277ms/step - loss: 0.2922 - accuracy: 0.9058 - val_loss: 0.0200 - val_accuracy: 0.9958\n",
            "Epoch 16/20\n",
            "1285/1285 [==============================] - 360s 280ms/step - loss: 0.2684 - accuracy: 0.9151 - val_loss: 0.0246 - val_accuracy: 0.9934\n",
            "Epoch 17/20\n",
            "1285/1285 [==============================] - 359s 280ms/step - loss: 0.2664 - accuracy: 0.9156 - val_loss: 0.0332 - val_accuracy: 0.9899\n",
            "Epoch 18/20\n",
            "1285/1285 [==============================] - 347s 270ms/step - loss: 0.2574 - accuracy: 0.9148 - val_loss: 0.0363 - val_accuracy: 0.9897\n",
            "Epoch 19/20\n",
            "1285/1285 [==============================] - 359s 280ms/step - loss: 0.2600 - accuracy: 0.9172 - val_loss: 0.0231 - val_accuracy: 0.9941\n",
            "Epoch 20/20\n",
            "1285/1285 [==============================] - 341s 266ms/step - loss: 0.2464 - accuracy: 0.9223 - val_loss: 0.0152 - val_accuracy: 0.9977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f17d801cb20>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "classifier.fit(training_set,\n",
        "                  epochs = 20,\n",
        "                  validation_data = test_set)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2_json = classifier.to_json()\n",
        "with open(\"model2_new.json\", \"w\") as json_file:\n",
        "    json_file.write(model2_json)\n",
        "print('Model Saved')\n",
        "classifier.save_weights('model2_new.h5')\n",
        "print('Weights saved')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLCObfC-Fn6x",
        "outputId": "0de1a2df-44a1-4e14-f6e9-670a4a50925d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved\n",
            "Weights saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/model2_new.h5' '/content/drive/MyDrive'"
      ],
      "metadata": {
        "id": "e5dQrQ8OmGYc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6rc1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}